# Gesture Control Robot
This project uses the gestures of your hand movements to control the direction and speed of the car 
| **Engineer** | **School** | **Area of Interest** | **Grade** |
|:--:|:--:|:--:|:--:|
| Kameron N | Courtland Highschool | Electrical Engineering | Incoming Senior

![Headstone Image](https://bluestampengineering.com/wp-content/uploads/2016/05/improve.jpg)
  
# Final Milestone
My final milestone is allowing the bluetooth to read gestures from the accelorometer and have the car be able to move foward and backwards. After getting my car built and wired up to the arduino, H bridge and motors the last thing i needed was for the ADXL345 to communicate the chracters of the gestures to the robot. Once I got the accelormeter, which reads gestures, to connect to my blutooth and allow the arduino micro to read the code. This allowed the car to move based off the gestures of the accelerometer

[![Final Milestone]
<iframe width="560" height="315" src="https://www.youtube.com/embed/4Pcw4EDEFpg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

# First Milestone
My first milestone was configuring the accelerometer to to my arduino uno allowing it to read the acceleration and tilt needed to make my car. After many tries I was able to read my XYZ values on the serial monitor for Arduino IDE. Using ADXL345 and installing its software I used a sensortest to test the values. 

[![First Milestone]
<iframe width="560" height="315" src="https://www.youtube.com/embed/q0oDf7IUYQs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
